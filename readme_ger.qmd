---
date-modified: today
mermaid-format: png
format: 
  gfm:
    output-file: "README"
    output-ext: md
execute: 
  echo: false 
  warning: false
---


# Projektübersicht: Nutzungsmsuter im Pariser Velib System

Dieses Projekt analysiert die Dynamik des Pariser Velib Bike-Sharing-Systems. Ich verwende Cluster-Analyse sowie räumliche und zeitliche Visualisierungen, um Muster im Fahrradfluss innerhalb des Netzwerks getrennt für Wochentage und Wochenenden aufzudecken. Beide Zeitperioden weisen recht unterschiedliche Dynamiken auf.

# Datensatz

Der Datensatz besteht aus zwei Tabellen: eine enthält allgemeine Informationen (ID, Name, Standort etc.) für alle Stationen und eine weitere beinhaltet die Anzahl der verfügbaren Fahrräder an einer bestimmten Station zu einem bestimmten Zeitpunkt.

Die Daten wurden vom 01.07.2024 bis 11.02.2025 über den `General Bikeshare Feed` des Velib-Systems erhoben (verfügbar unter: [https://www.velib-metropole.fr/donnees-open-data-gbfs-du-service-velib-metropole](https://www.velib-metropole.fr/donnees-open-data-gbfs-du-service-velib-metropole)). Der Feed wurde mithilfe des Python-Pakets [`gbfs-client`](https://github.com/jakehadar/bikeshare-client-python) abgefragt. Die Abfrage des Feeds erfolgte in einem Zeitintervall von 5 Minuten.

Nach dem "Unnesting" wurden die neu erfassten Daten in eine lokale `sqlite`-Datenbank geschrieben.

Das ursprüngliche Skript ist unter [./archive/server.py](./archive/server.py) verfügbar.

Die Datenerfassung wurde aufgrund einer Schemaänderung im Feed gestoppt. Eine neue Implementierung unter Verwendung von `dlt` ist in Vorbereitung.

Der Zeitreihen-Datensatz enthält 87 047 062 Einträge.

# Tools

- data load tool `dlt`: data ingestion (local `sqlite` database to AWS `Athena`, recurrent querying of the GBFS feed for future data acquisition)
- data build tool `dbt`: data transformation
- AWS `Quicksight`: dashboarding
- python libraries for data processing: `pandas`, `scikit-learn`


# Schema der Datenpipeline

![](./img/mermaid-diagram-2025-04-27-214223.png)

# Datenbearbeitung

Der Datensatz wurde gefiltert, um den Zeitraum vom 15.07.2024 bis 31.08.2024 auszuschließen, währenddessen die Olympischen Sommerspiele in Paris stattfanden. Diese verursachten wahrscheinlich erhebliche Veränderungen der täglichen Fahrradnutzungsmuster, sowohl aufgrund unterschiedlicher Fahrprofile und Verlagerungsstrategien als auch durch die Einrichtung temporärer Stationen.

Für jeden Zeitpunkt und jede Station wurde die relative Belegung der Station berechnet, indem die Anzahl der verfügbaren Fahrräder (`num_bikes_available`) durch die Summe aus der Anzahl der verfügbaren Fahrräder und der verfügbaren Docks (`num_docks_availabe`) geteilt wurde ([siehe auch dbt-Modelle](./dbt/athena_/models/)).

Die relative Belegung wurde dann für jede Station nach der Stunde des Tages gemittelt ([siehe zum Beispiel](./analysis/paris/rel_avail_weekdays/rel_avail_data.py)).

Separate Datensätze wurden für Wochentage und das Wochenende erstellt.

# Dashboard

AWS Quicksight Dashboard, AWS Account erforderlich

[![](./dashboard.png)](https://eu-central-1.quicksight.aws.amazon.com/sn/accounts/887794525971/dashboards/00415383-4ae1-440b-897c-0f054ed9df20?directory_alias=kantundpeterpan)

# Results

```{python}
#| echo: false
import sys
import os
import pandas as pd
import geopandas
import matplotlib.pyplot as plt
import seaborn as sns
import folium
from folium.plugins import HeatMap
import contextily as ctx
import numpy as np
import matplotlib.gridspec as gridspec
```

## Netzwerkdynamik an Wochentagen

```{python}

# Load the saved data
wcss_df = pd.read_csv('./analysis/paris/rel_avail_weekdays/wcss_results.csv')
cluster_profiles_df = pd.read_csv('./analysis/paris/rel_avail_weekdays/cluster_profiles.csv', index_col=0)
cluster_sizes_df = pd.read_csv('./analysis/paris/rel_avail_weekdays/cluster_sizes.csv', index_col=0)
stations_clusters_with_info_df = pd.read_csv('./analysis/paris/rel_avail_weekdays/station_clusters_with_info.csv')
stations_clusters_with_info_df = geopandas.GeoDataFrame(
    stations_clusters_with_info_df, geometry=geopandas.points_from_xy(
        stations_clusters_with_info_df['lon'], stations_clusters_with_info_df['lat']
    ), crs = "EPSG:4326"
)
# stations_clusters_with_info_df.set_crs(2154)
```


```{python}
n_clusters = cluster_profiles_df.shape[0] # Get n_clusters from the loaded data
fontsize = 16 # Adjust as necessary to keep relative size between elements
# Create a gridspec layout
fig = plt.figure(figsize=(15, 20))
gs = gridspec.GridSpec(8, 2) # 8 rows, 2 columns
# Panel 1: Elbow Method (Span 2x1)
ax1 = plt.subplot(gs[0:2, 0])  # Span rows 0 and 1, column 0
ax1.plot(wcss_df['n_clusters'], wcss_df['wcss'])
ax1.set_title('Elbow Method', fontsize=fontsize)
ax1.set_xlabel('Number of clusters', fontsize=fontsize)
ax1.set_ylabel('WCSS', fontsize=fontsize)
ax1.tick_params(axis='both', which='major', labelsize=fontsize-2)
ax1.tick_params(axis='both', which='minor', labelsize=fontsize-2)

# Panel 2: Cluster Profiles (Span 2x1)
ax2 = plt.subplot(gs[0:2, 1])  # Span rows 0 and 1, column 1
palette = sns.color_palette("hls", n_clusters)
for i in range(n_clusters):
    ax2.plot(cluster_profiles_df.iloc[i], label=f'Cluster {i+1}', color=palette[i])
ax2.set_title('Cluster Profiles (Average Availability per Hour)', fontsize=fontsize)
ax2.set_xlabel('Hour', fontsize=fontsize)
ax2.set_ylabel('Average Relative Availability', fontsize=fontsize)
ax2.set_xticklabels(range(24), fontsize=fontsize-2)
ax2.tick_params(axis='y', which='major', labelsize=fontsize-2)

ax2.legend(fontsize=fontsize-4)
ax2.grid(True)

# Panel 3: Cluster Sizes (Span 2x1)
ax3 = plt.subplot(gs[2:4, 0])  # Span rows 2 and 3, column 0
cluster_sizes_df.sort_index().plot(kind='bar', ax=ax3, legend=False)
ax3.set_title('Cluster Sizes', fontsize=fontsize)
ax3.set_xlabel('Cluster', fontsize=fontsize)
ax3.set_ylabel('Number of Stations', fontsize=fontsize)
ax3.tick_params(axis='both', which='major', labelsize=fontsize-2)
ax3.tick_params(axis='both', which='minor', labelsize=fontsize-2)


# Panel 4: Cluster Heatmap (Span 2x1)
ax4 = plt.subplot(gs[2:4, 1])  # Span rows 2 and 3, column 1
sns.heatmap(cluster_profiles_df, cmap="YlGnBu", ax=ax4)
ax4.set_title("Heatmap of Average Availability by Cluster", fontsize=fontsize)
ax4.set_xlabel('Hour', fontsize=fontsize)
ax4.set_ylabel("Cluster", fontsize=fontsize)
ax4.set_xticklabels(range(24), fontsize=fontsize-2)
ax4.set_yticklabels(ax4.get_yticklabels(), fontsize=fontsize-2, rotation=0)
# Panel 5: Geographic Distribution of Clusters (Span 4x4)
ax5 = plt.subplot(gs[4:8, :])  # Span rows 4, 5, 6 and 7, and both columns
# sns.scatterplot(
#     x='lon',
#     y='lat',
#     hue='cluster',
#     palette=sns.color_palette("hls", n_clusters),
#     data=stations_clusters_with_info_df,
#     ax=ax5,
#     s=20 # Adjust marker size
# )
gdf_webmercator = stations_clusters_with_info_df.to_crs(epsg=3857)
# First, create a dictionary to map cluster numbers to colors
cluster_colors = {i: color for i, color in enumerate(sns.color_palette("hls", n_colors=n_clusters))}

# Then, plot using the map
gdf_webmercator.plot(ax=ax5, c=gdf_webmercator['cluster'].subtract(1).map(cluster_colors))
ax5.set_title('Geographic Distribution of Clusters', fontsize=fontsize)
ax5.set_xlabel('Longitude', fontsize=fontsize)
ax5.set_ylabel('Latitude', fontsize=fontsize)
ax5.set_aspect('equal', adjustable='datalim') # Keep aspect ratio for map
ctx.add_basemap(ax5, crs =gdf_webmercator.crs.to_string(), source=ctx.providers.CartoDB.Positron)
ax5.set_xticks([])
ax5.set_yticks([])
ax5.spines['top'].set_visible(False)
ax5.spines['right'].set_visible(False)
ax5.spines['left'].set_visible(False)
ax5.spines['bottom'].set_visible(False)
ax5.set_xlabel('')
ax5.set_ylabel('')
plt.tight_layout()  # Adjust layout to prevent overlapping subplots

```


Die Anzahl der Cluster wurde mithilfe der Elbow-Methode ermittelt. Es gibt kein eindeutiges Ergebnis, aber eine Wahl von $k=5$ scheint gerechtfertigt, da sie eine sinnvolle Unterscheidung von zeitlichen Mustern und geografischen Konzentrationen ermöglichte, die mit erwartetem städtischen Mobilitätsverhalten übereinstimmen und eine kohärente Grundlage für die Analyse bieten.

Angesichts der fünf Cluster zeigt die zeitliche Analyse der stündlichen mittleren relativen Auslastung im Verlauf eines typischen Arbeitstages interessante Dynamiken.

Mit etwa 500 Stationen ist Cluster Nr. 1 der größte und entspricht in etwa 30 % aller verfügbaren Stationen im Netz. Die mittlere Auslastung in diesem Cluster überschreitet nie 30 % und ist während der Arbeitszeit (8 bis 20 Uhr) sehr niedrig (<20 %). Die Stationen des Clusters 1 liegen hauptsächlich im äußeren Ring der Pariser Arrondissements auf der rechten Seinseite (Arrs. 17, 18, 19, 20) und in den Arrondissements 13 und 14 auf der linken Seineseite.

Die mittlere Auslastung in Cluster 2 ist mit 60-70% über den Tag hinweg recht stabil. Die Stationen, die Cluster 2 zugeordnet sind, konzentrieren sich auf zwei Regionen von Paris: 1) Im östlichen Teil des inneren Ring (3., 4. und 5. Arrondissement) und 2) Im äußeren südwestlichen Teil, um und südlich des Eiffelturms, was auf eine höhere Nachfrage in Touristengebieten in Kombination mit der regulären Nachfrage von Einwohnern hindeuten könnte.

Die verbleibenden Cluster 3, 4 und 5 zeigen antikorrelierte periodische Muster mit ausgeprägten Änderungen der Auslastung während der Pendelzeiten (6-9 Uhr und 16-18 Uhr). Stationen in den Arrondissements 6, 7 und 8 (Cluster 4) sind am Morgen kaum belegt und verzeichnen einen starken Anstieg der Auslastung, was auf einen Einstrom von Pendlers aus den Clustern 3 und 5 hindeutet.

Es muss beachtet werden, dass dieser Datensatz nur Rückschlüsse über Nettoflüsse analysiert werden können, d. h. der Flussweg kann aus diesen Daten nicht abgeleitet werden. Dies bedeutet, dass Abflüsse aus den Clustern 3 und 5 am Morgen direkt in Cluster 4 gehen könnten, während ein Flussgleichgewicht zwischen den Clustern 3, 5, 2 und 4 als Erklärung für das beobachtete Muster ebenfalls in Betracht kommt.

Selbst mit dieser Einschränkung können die beobachteten Flussmuster Aufschluss geben bezüglich bestimmter Charakteristika der gefundenen Stationcluster:

Stationen oder Cluster, die während des morgendlichen Berufsverkehrs einen signifikanten Rückgang der verfügbaren Fahrräder aufweisen, deuten auf ein hohes Volumen an Netto-Ausleihen hin, was typisch für Pendleraktivitäten ist. Stationen oder Cluster, die während der Abendstunden einen starken Anstieg der verfügbaren Fahrräder zeigen, deuten auf einen Netto-Einfluss von Fahrrädern hin (mehr Rückgaben als Ausleihen), potenziell von Benutzern, die Fahrräder nach der Arbeit oder Freizeit zurückgeben.

Stationen mit einem konstantem Nettorückgang während der Spitzennutzung sollten für aktive Auffüllung in Betracht gezogen werden, während Fahrräder von Stationen abgezogen werden sollten, die sich nahe der vollen Auslastung befinden.


## Netwerkdynamik am Wochenende


```{python}

# Load the saved data
wcss_df = pd.read_csv('./analysis/paris/rel_avail_weekend/wcss_results.csv')
cluster_profiles_df = pd.read_csv('./analysis/paris/rel_avail_weekend/cluster_profiles.csv', index_col=0)
cluster_sizes_df = pd.read_csv('./analysis/paris/rel_avail_weekend/cluster_sizes.csv', index_col=0)
stations_clusters_with_info_df = pd.read_csv('./analysis/paris/rel_avail_weekend/station_clusters_with_info.csv')
stations_clusters_with_info_df = geopandas.GeoDataFrame(
    stations_clusters_with_info_df, geometry=geopandas.points_from_xy(
        stations_clusters_with_info_df['lon'], stations_clusters_with_info_df['lat']
    ), crs = "EPSG:4326"
)
# stations_clusters_with_info_df.set_crs(2154)
```

```{python}
n_clusters = cluster_profiles_df.shape[0] # Get n_clusters from the loaded data
fontsize = 16 # Adjust as necessary to keep relative size between elements
# Create a gridspec layout
fig = plt.figure(figsize=(15, 20))
gs = gridspec.GridSpec(8, 2) # 8 rows, 2 columns
# Panel 1: Elbow Method (Span 2x1)
ax1 = plt.subplot(gs[0:2, 0])  # Span rows 0 and 1, column 0
ax1.plot(wcss_df['n_clusters'], wcss_df['wcss'])
ax1.set_title('Elbow Method', fontsize=fontsize)
ax1.set_xlabel('Number of clusters', fontsize=fontsize)
ax1.set_ylabel('WCSS', fontsize=fontsize)
ax1.tick_params(axis='both', which='major', labelsize=fontsize-2)
ax1.tick_params(axis='both', which='minor', labelsize=fontsize-2)

# Panel 2: Cluster Profiles (Span 2x1)
ax2 = plt.subplot(gs[0:2, 1])  # Span rows 0 and 1, column 1
palette = sns.color_palette("hls", n_clusters)
for i in range(n_clusters):
    ax2.plot(cluster_profiles_df.iloc[i], label=f'Cluster {i+1}', color=palette[i])
ax2.set_title('Cluster Profiles (Average Availability per Hour)', fontsize=fontsize)
ax2.set_xlabel('Hour', fontsize=fontsize)
ax2.set_ylabel('Average Relative Availability', fontsize=fontsize)
ax2.set_xticklabels(range(24), fontsize=fontsize-2)
ax2.tick_params(axis='y', which='major', labelsize=fontsize-2)

ax2.legend(fontsize=fontsize-4)
ax2.grid(True)

# Panel 3: Cluster Sizes (Span 2x1)
ax3 = plt.subplot(gs[2:4, 0])  # Span rows 2 and 3, column 0
cluster_sizes_df.sort_index().plot(kind='bar', ax=ax3, legend=False)
ax3.set_title('Cluster Sizes', fontsize=fontsize)
ax3.set_xlabel('Cluster', fontsize=fontsize)
ax3.set_ylabel('Number of Stations', fontsize=fontsize)
ax3.tick_params(axis='both', which='major', labelsize=fontsize-2)
ax3.tick_params(axis='both', which='minor', labelsize=fontsize-2)


# Panel 4: Cluster Heatmap (Span 2x1)
ax4 = plt.subplot(gs[2:4, 1])  # Span rows 2 and 3, column 1
sns.heatmap(cluster_profiles_df, cmap="YlGnBu", ax=ax4)
ax4.set_title("Heatmap of Average Availability by Cluster", fontsize=fontsize)
ax4.set_xlabel('Hour', fontsize=fontsize)
ax4.set_ylabel("Cluster", fontsize=fontsize)
ax4.set_xticklabels(range(24), fontsize=fontsize-2)
ax4.set_yticklabels(ax4.get_yticklabels(), fontsize=fontsize-2, rotation=0)
# Panel 5: Geographic Distribution of Clusters (Span 4x4)
ax5 = plt.subplot(gs[4:8, :])  # Span rows 4, 5, 6 and 7, and both columns
# sns.scatterplot(
#     x='lon',
#     y='lat',
#     hue='cluster',
#     palette=sns.color_palette("hls", n_clusters),
#     data=stations_clusters_with_info_df,
#     ax=ax5,
#     s=20 # Adjust marker size
# )
gdf_webmercator = stations_clusters_with_info_df.to_crs(epsg=3857)
# First, create a dictionary to map cluster numbers to colors
cluster_colors = {i: color for i, color in enumerate(sns.color_palette("hls", n_colors=n_clusters))}

# Then, plot using the map
gdf_webmercator.plot(ax=ax5, c=gdf_webmercator['cluster'].subtract(1).map(cluster_colors))
ax5.set_title('Geographic Distribution of Clusters', fontsize=fontsize)
ax5.set_xlabel('Longitude', fontsize=fontsize)
ax5.set_ylabel('Latitude', fontsize=fontsize)
ax5.set_aspect('equal', adjustable='datalim') # Keep aspect ratio for map
ctx.add_basemap(ax5, crs =gdf_webmercator.crs.to_string(), source=ctx.providers.CartoDB.Positron)
ax5.set_xticks([])
ax5.set_yticks([])
ax5.spines['top'].set_visible(False)
ax5.spines['right'].set_visible(False)
ax5.spines['left'].set_visible(False)
ax5.spines['bottom'].set_visible(False)
ax5.set_xlabel('')
ax5.set_ylabel('')
plt.tight_layout()  # Adjust layout to prevent overlapping subplots

```

Die Elbow-Methode für die Wochenenddaten deutet darauf hin, dass eine Analyse mit nur zwei Clustern gerechtfertigt sein könnte. Um jedoch den direkten Vergleich zur Wochentagsanalyse zu erleichtern, wurden 5 Cluster beibehalten.

Zusätzlich wurden die in der Wochenendanalyse gefundenen Cluster manuell umbenannt (die Clusterzugehörigkeit der Stationen wurde nicht verändert), um Unterschiede in den Nutzungsmustern und Ähnlichkeiten bei der räumlichen Verteilung der Stationen hervorzuheben, während sich die Nutzungsmuster von denen unter der Woche unterscheiden.

Die Ergebnisse für Cluster 1 und 2 bezüglich der zeitlichen Auslastungsmuster und Clustersize sind denen an Werktagen sehr ähnlich. Insgesamt zeigen die Cluster 1, 2, 3 und 5 interkorrelierte Auslastungsmuster mit einer deutlich geringeren Amplitude im Vergleich zu Wochentagen, besonders auffällig in den Clustern 3 und 5, was auf weniger extreme Schwankungen in der Fahrradverfügbarkeit hindeutet.

Wie an Wochentagen ist das im Cluster 4 gefundene Muster antikorreliert zur Auslastung in den restlichen Clustern. Im Vergleich zu Wochentagen ist die Fahrradverfügbarkeit höher und die Veränderung der Verfügbarkeit während der Stunden nach Mitternacht ausgeprägter, während der Netto-Spitzenzufluss in den späten Nachmittag verschoben ist.

Dies könnte auf heimkehrende Nutzer zurückzuführen sein, die den Abend und einen Teil der Nacht auswärts verbracht haben, was mit der Konzentration von Stationen in Cluster 4 in belebten Innenstadtvierteln kohärent ist. 
Die im Vergleich zu Wochentagen abgeflachten Muster in den übrigen Clustern deuten entweder auf eine generell niedrigere Nutzeraktivität am Wochenende hin oder auf in homogenere Verteilung von Fahrten über das Stadtgebiet.

# Schlussfolgerung und Ausblick

Diese Analyse untersucht zeitliche Muster von Fahrradverfügbarkeit im Pariser Velib-Fahrradleihsystem. Ich habe gezeigt, dass ein großer Teil des Netzwerks unterversorgt ist (Cluster 1 in sowohl an Wochentagen als auch am Wochenende), während ein anderer Teil einen kontinuierlich stabilen Zugang zu Fahrrädern bietet (Cluster 2).

Diese Ergebnisse könntent als Anhaltspunkte für potenzielle Maßnahmen zur Umlagerung (mehr Fahrräder nach Cluster 1 verlagern) und potenzielle Infrastrukturverbesserungen (mehr Station in oder alternative Rückgabelösungen in Cluster 4) dienen.

Der Vergleich der Auslastungsmuster aufgeschlüsselt nach Werktag / Wochendende zeigt vor allem Unterschiede im Zeitverlauf weniger in der räumlichen Konzentration von Stationen mit ähnlichem Auslastungsverlauf. Dies deutet auf zwei unterschiedliche Zustände des Fahrradleihsystems hin, denen in weiteren detaillierten Analysen nachgegangen werden könnte, inbesondere bezüglich der potenziellen WendepunkteÖ Freitagabend und Montagmorgen.


<!-- # Outlook

## Occupancy analysis
- per district/city
- correlation with sociodemographic indicators (salary, age, level of education, total population)
- correlation with station elevation
- stratified analysis mechanical/ebikes
- correlation and (lagged) crosscorrelation
- clustering comparison metrics ari, nmi
- banlieue vs. intramuros
- analysis per weekday with emphasis on change points

## Network structure analysis (solely based on stations)

- theoretical capacity -->